{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unifying two datasets into one\n",
    "\n",
    "- Football-Player-Detection (v8-resized1280_tile2x2_aug3x.yolov5pytorch)\n",
    "    - Classes: football, player (one image marked null)\n",
    "    - Resized to 1280x1280 (Stretch)\n",
    "    - Normalised bb\n",
    "    - very Augmented training set\n",
    "- SOD_Dataset\n",
    "    - Classes: ball, player\n",
    "    - Annotations: For each image, there is a text file containing the class ID, Xmin, Ymin, Xmax, and Ymax, respectively.\n",
    "    - yolov5_annotations: Box coordinates are in normalized xywh format (from 0 - 1) for yolov5_annotations. x_center and width are divided by image width, and y_center and height by image height.\n",
    "\n",
    " \n",
    " # Final dataset\n",
    " - Classes: football, player\n",
    " - Resized to 1280x1280 (Stretch)\n",
    " - Annotations: For each image, there is a text file containing the class ID, Xmin, Ymin, Xmax, and Ymax, respectively. (bottom left, top right corners ?Â¿)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Important Note\n",
    "The two oringinal datasets must be downloaded into a \"Datasets\" folder in the parent folder of the repository:\n",
    "\n",
    "Download from:\n",
    "- https://github.com/FootballAnalysis/footballanalysis/tree/main/Dataset/Object%20Detection%20Dataset\n",
    "- https://universe.roboflow.com/augmented-startups/football-player-detection-kucab\n",
    "\n",
    "And name, respectively:\n",
    "- SOD_Dataset\n",
    "- Football-Player-Detection\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create new directory for concatenated dataset\n",
    "new_dataset_dir = \"Datasets/Concatenated_Dataset/\"\n",
    "os.makedirs(new_dataset_dir, exist_ok = True)\n",
    "\n",
    "image_final_dir = \"Datasets/Concatenated_Dataset/images/\"\n",
    "os.makedirs(image_final_dir, exist_ok = True)\n",
    "\n",
    "label_final_dir = \"Datasets/Concatenated_Dataset/annotations/\"\n",
    "os.makedirs(label_final_dir, exist_ok = True)\n",
    "\n",
    "new_file_name = \"Sample_\"\n",
    "sample_n = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping SOD_Dataset and switching labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set the path to your image directory\n",
    "image_dir = \"Datasets/SOD_Dataset/images\"\n",
    "# Set the path to your label directory\n",
    "label_dir = \"Datasets/SOD_Dataset/annotations\"\n",
    "\n",
    "new_size = (1280, 1280)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    # Open the image file using PIL\n",
    "    img = Image.open(os.path.join(image_dir, filename))\n",
    "\n",
    "    # Resize image\n",
    "\n",
    "    new_image = img.resize(new_size)\n",
    "    new_image.save(os.path.join(image_final_dir, new_file_name + str(sample_n) + \".jpg\"))\n",
    "\n",
    "    # Open the corresponding label file\n",
    "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "    label_path = os.path.join(label_dir, label_filename)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        label_data = f.readlines()\n",
    "     # Resize the bounding boxes in the label file\n",
    "    new_label_data = []\n",
    "    for line in label_data:\n",
    "        parts = line.strip().split(\" \")\n",
    "        class_id = parts[0]\n",
    "        bounding_box = parts[1:]\n",
    "\n",
    "        x_min = float(bounding_box[0])\n",
    "        y_min = float(bounding_box[1])\n",
    "        x_max = float(bounding_box[2])\n",
    "        y_max = float(bounding_box[3])\n",
    "        \n",
    "        # Resize the bounding box coordinates\n",
    "        x_min_resized = int(x_min * (new_size[0] / img.width))\n",
    "        y_min_resized = int(y_min * (new_size[1] / img.height))\n",
    "        x_max_resized = int(x_max * (new_size[0] / img.width))\n",
    "        y_max_resized = int(y_max * (new_size[1] / img.height))\n",
    "        \n",
    "        # Change class id to match other dataset:\n",
    "        new_class_id = class_id # in case there is any null \n",
    "        if class_id == '0':\n",
    "            new_class_id = '1'\n",
    "        elif class_id == '1': \n",
    "            new_class_id = '0'\n",
    "        \n",
    "        new_parts = [new_class_id, str(x_min_resized), str(y_min_resized), str(x_max_resized), str(y_max_resized)]\n",
    "        new_label_data.append(\" \".join(new_parts))\n",
    "    \n",
    "        output_label_filename = os.path.splitext(new_file_name + str(sample_n))[0] + \".txt\"\n",
    "        output_label_path = os.path.join(label_final_dir, output_label_filename)\n",
    "        with open(output_label_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(new_label_data))\n",
    "    \n",
    "    sample_n += 1\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Bounding boxes in  Football-Player-Detection to correct format and joining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the path to your image directory\n",
    "image_directories = [\"Datasets/Football-Player-Detection/train/images\", \"Datasets/Football-Player-Detection/test/images\", \"Datasets/Football-Player-Detection/valid/images\"]\n",
    "\n",
    "# Set the path to your label directory\n",
    "label_dirrectories = [\"Datasets/Football-Player-Detection/train/labels\", \"Datasets/Football-Player-Detection/test/labels\", \"Datasets/Football-Player-Detection/valid/labels\"]\n",
    "\n",
    "\n",
    "for image_dir, label_dir in zip(image_directories, label_dirrectories):\n",
    "    # Loop through each image file in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        #  MAYBE LATER ALSO RESIZE; BUT THIS IS FASTER NOW\n",
    "        # new_image = img.resize(new_size)\n",
    "        # new_image.save(os.path.join(image_final_dir, new_file_name + str(sample_n) + \".jpg\"))\n",
    "        original_im_dir = os.path.join(image_dir, filename)\n",
    "        target_im_dir = os.path.join(image_final_dir, new_file_name + str(sample_n) + \".jpg\")\n",
    "        \n",
    "        shutil.copy(original_im_dir, target_im_dir)\n",
    "\n",
    "        # Open the corresponding label file\n",
    "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        label_path = os.path.join(label_dir, label_filename)\n",
    "        with open(label_path, \"r\") as f:\n",
    "            label_data = f.readlines()\n",
    "        # Resize the bounding boxes in the label file\n",
    "            # Resize the bounding boxes in the label file\n",
    "        new_label_data = []\n",
    "        for line in label_data:\n",
    "            parts = line.strip().split(\" \")\n",
    "            x_center = float(parts[1])\n",
    "            y_center = float(parts[2])\n",
    "            box_width = float(parts[3])\n",
    "            box_height = float(parts[4])\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            x_min = int((x_center - (box_width / 2)) * img.width)\n",
    "            y_min = int((y_center - (box_height / 2)) * img.height)\n",
    "            x_max = int((x_center + (box_width / 2)) * img.width)\n",
    "            y_max = int((y_center + (box_height / 2)) * img.height)\n",
    "            \n",
    "            new_parts = [parts[0], str(x_min), str(y_min), str(x_max), str(y_max)]\n",
    "            new_label_data.append(\" \".join(new_parts))\n",
    "        \n",
    "            output_label_filename = os.path.splitext(new_file_name + str(sample_n))[0] + \".txt\"\n",
    "            output_label_path = os.path.join(label_final_dir, output_label_filename)\n",
    "            with open(output_label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(new_label_data))\n",
    "\n",
    "        sample_n += 1\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dan's Framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# this function is for the DataLoader, it makes sure the tensors within a batch are the same dimension (don't ask how, I don't know)\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "# this is a class that loads the data, according to how pytorch wants it\n",
    "class playersDataset(Dataset): # dataset is the path\n",
    "    def __init__(self, folder_path, img_size=416):\n",
    "        self.root = folder_path\n",
    "        self.images_folder = os.path.join(folder_path, \"images\")\n",
    "        self.labels_folder = os.path.join(folder_path, \"annotations\")\n",
    "        \n",
    "        self.image_files = os.listdir(self.images_folder)\n",
    "        self.label_files = os.listdir(self.labels_folder)\n",
    "\n",
    "        self.convert_tensor = transforms.ToTensor()\n",
    "\n",
    "    def readLabelsFile(self, file_path, index):\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        areas = []\n",
    " \n",
    "        with open(file_path) as f:\n",
    "            for row in f:\n",
    "                annotation = [float(x) for x in row.split()]\n",
    "                #print(annotation)\n",
    "                labels.append(int(annotation[0]))\n",
    "                [x0, y0, x1, y1] = annotation[1:5]\n",
    "                boxes.append([x0, y0, x1, y1])\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)         \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        areas = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\" : boxes,\n",
    "            \"labels\" : labels,\n",
    "            \"image_id\" : torch.tensor(index),\n",
    "            \"area\" : areas,\n",
    "            \"iscrowd\" : iscrowd\n",
    "            }\n",
    "\n",
    "        return target\n",
    "\n",
    "\n",
    "    # pytorch needs this, it returns a single (image, output) pair\n",
    "    def __getitem__(self, index):\n",
    "        # load and format the image file as a tensor\n",
    "        \n",
    "        imgPath = os.path.join(self.images_folder, self.image_files[index])\n",
    "        img = Image.open(imgPath)\n",
    "\n",
    "        # TEMPORARY - REMOVE THIS LATER, WE SHOULD DECIDE HOW LARGE THE IMAGES ARE\n",
    "        img = img.resize((1080, 1920))\n",
    "\n",
    "        input_img = self.convert_tensor(img)\n",
    "\n",
    "        # load and format the corresponding labels\n",
    "        labelPath = os.path.join(self.labels_folder, self.label_files[index])\n",
    "        target = self.readLabelsFile(labelPath, index)\n",
    "        \n",
    "        return input_img, target\n",
    "\n",
    "    # pytorch also needs the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"Datasets/Concatenated_Dataset/\"\n",
    "dataset = playersDataset(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Define the size of each set\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "# CHECK BETTER\n",
    "# Define the random samplers for each set\n",
    "# SubsetRandomSampler: Samples elements randomly from a given list of indices, without replacement.\n",
    "train_sampler = SubsetRandomSampler(range(train_size))\n",
    "val_sampler = SubsetRandomSampler(range(train_size, train_size + val_size))\n",
    "test_sampler = SubsetRandomSampler(range(train_size + val_size, len(dataset)))\n",
    "\n",
    "# Define the dataloaders for each set\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
